{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "Unige DL2019 - Copy of Test_Colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "RFCC8nr27Qns"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mallibus/Unige-DL2019/blob/master/Unige_DL2019_Copy_of_Test_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFcf7Lbf7Qm1",
        "colab_type": "text"
      },
      "source": [
        "# Lab 0. Introduction to Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNeH0hmL7Qm5",
        "colab_type": "text"
      },
      "source": [
        "## 0.1 Basics of TensorFlow\n",
        "<img src=\"http://mlclass.epizy.com/lab0_images_notebook/tf_logo.png\" width=\"200px\"><br>\n",
        "TensorFlow is an open source machine learning library for research and production.<br>\n",
        "It offers tools, libraries and resources that makes it easy for you to build and deploy ML models.\n",
        "\n",
        "### Most important features:\n",
        "* Easy model building<br>\n",
        "Build and train ML models easily using intuitive high-level APIs like Keras with eager execution, which makes for immediate model iteration and easy debugging.\n",
        "\n",
        "\n",
        "* Robust ML production anywhere<br>\n",
        "Easily train and deploy models in the cloud, on-prem, in the browser, or on-device no matter what language you use.\n",
        "\n",
        "\n",
        "* Powerful experimentation for research<br>\n",
        "A simple and flexible architecture to take new ideas from concept to code, to state-of-the-art models, and to publication faster.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRGdWdQF7Qm8",
        "colab_type": "text"
      },
      "source": [
        "### Import TensorFlow\n",
        "In this tutorial is used **version 1.13.1** that is the last stable version released.<br>\n",
        "Recently version 2.0 is released but is still a preview."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkzXJp7O7Qm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "import time, h5py, os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
        "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KgI_bXk7QnD",
        "colab_type": "text"
      },
      "source": [
        "### Data representation for neural network\n",
        "A Tensor consists of a set of primitive values shaped into an array of any number of dimensions.<br>\n",
        "Similar to NumPy ndarray objects, Tensor objects have a data type and a shape.  <br>\n",
        "TensorFlow offers a rich library of operations (tf.add, tf.matmul, tf.linalg.inv etc.) that consume and produce Tensors; these operations automatically convert native Python types.<br>\n",
        "In addition, Tensors can be backed by accelerator memory (like GPU, TPU) and are immutable.<br>\n",
        "\n",
        "The rank of a tf.Tensor object defines its number of dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRpE40NC7QnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#RANK 0 (scalar)\n",
        "#Create tensor of type string with value \"hello world!\" \n",
        "#Create tensor of type int16 with value 17\n",
        "#Create tensor of type float64 with value 3.14159265359\n",
        "#Create tensor of type complex64 with value 10.1 - 1.5j\n",
        "\n",
        "t01 = tf.Variable(\"hello world!\", tf.string)\n",
        "print(\"RANK 0\\n\",t01,\"\\n\")\n",
        "\n",
        "\n",
        "#RANK 1 (vector)\n",
        "#Create tensor of type string with value \"abba\" \n",
        "#Create tensor of type float32 with value [6.14, 3.001]\n",
        "#Create tensor of type int32 with value [1,3,5,7]\n",
        "#Create tensor of type complex64 with value [10.3 - 4.05j, 3.1 - 2.13j]\n",
        "\n",
        "t11 = tf.Variable([\"abba\"], tf.string)\n",
        "print(\"RANK 1\\n\",t11,\"\\n\")\n",
        "\n",
        "\n",
        "#RANK 2 (matrix)\n",
        "#Create tensor of type int16 with values [7,4] in the first row and [11,1] in the second row \n",
        "#Create tensor of type bool with values [False,True] in the first row and [True,False] in the second row \n",
        "#Create tensor of type int32 with value [3] in the first row,[2] in the second row,[12] in the third row,[4] in the fourth row\n",
        "#Create tensor of type float64 with values [0.1,11.2,4.01,3.5] in the first row and [0.2,1,22.1,3.12] in the second row \n",
        "\n",
        "t21 = tf.Variable([[7,4],[11,1]], tf.int16)\n",
        "print(\"RANK 2\\n\",t21,\"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV8gwP8I7QnY",
        "colab_type": "text"
      },
      "source": [
        "### Graphical Processing Unit (GPU)\n",
        "\n",
        "The basic architecture of a GPU differs a lot from a CPU; the GPU is optimized for a high computational power and a high throughput.\n",
        "\n",
        "<img src=\"http://mlclass.epizy.com/lab0_images_notebook/cpu_gpu.png\" width=\"500px\"><br>\n",
        "\n",
        "The computation of DNNs is a task that fits excellent on a GPU: there is a large amount of parallelism that can\n",
        "be utilized (the most common kernels are matrix multiply, convolution and functions with no data dependencies at\n",
        "all).<br>\n",
        "In TensorFlow, the supported device types are CPU and GPU; you could use also multiple-GPUs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIvqZ4f37QnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if tf.test.is_gpu_available():\n",
        "    print(\"GPU \",tf.test.gpu_device_name(), \" is available\\n\")\n",
        "    \n",
        "# Print list of available devices\n",
        "print(\"Devices available:\\n\\n\",device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkxGlghG7Qnd",
        "colab_type": "text"
      },
      "source": [
        "### Comparison of CPU time and GPU time \n",
        "Below there's an example of the computational time required in the different cases to do matrix multiplication.<br>\n",
        "**What do you expect? Which is faster? Why?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq2OOj0v7Qng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def measure(x, steps):\n",
        "    tf.matmul(x, x)\n",
        "    start = time.time()\n",
        "    for i in range(steps):\n",
        "        x = tf.matmul(x, x)\n",
        "          # tf.matmul can return before completing the matrix multiplication\n",
        "          # (e.g., can return after enqueing the operation on a CUDA stream).\n",
        "          # The x.numpy() call below will ensure that all enqueued operations have completed \n",
        "          # (and will also copy the result to host memory, so we're including a little more than \n",
        "          # just the matmul operation time).\n",
        "    _ = x.numpy()\n",
        "    end = time.time()\n",
        "    return end - start"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HviUhQx7Qnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shape = (1000, 1000)\n",
        "steps = 200\n",
        "\n",
        "print(\"Time to multiply a {} matrix by itself {} times:\".format(shape, steps))\n",
        "\n",
        "# Run on CPU:\n",
        "with tf.device(\"/cpu:0\"):\n",
        "    print(\"CPU: {} secs\".format(measure(tf.random_normal(shape), steps)))\n",
        "\n",
        "# Run on GPU, if available:\n",
        "if tf.test.is_gpu_available():\n",
        "    with tf.device(\"/gpu:0\"):\n",
        "        print(\"GPU: {} secs\".format(measure(tf.random_normal(shape), steps)))\n",
        "else:\n",
        "    print(\"GPU: not found\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7T4QGH17Qnr",
        "colab_type": "text"
      },
      "source": [
        "### Automatic Differentiation\n",
        "Automatic differentiation is a technique for optimizing machine learning models.<br>\n",
        "On simple terms, it is a way of automatically computing the derivatives of the output of a function using the **Chain Rule**   (https://en.wikipedia.org/wiki/Chain_rule ).<br>\n",
        "Almost every function can be computed as a composition of simple functions which have simple derivatives; consequently, you can compute the derivative of any function that can be written as composition of simpler functions.<br>\n",
        "Tensorflow uses **Reverse Mode Differentiation**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFCC8nr27Qns",
        "colab_type": "text"
      },
      "source": [
        "#### Here you can find a quick explanation on how backpropagation work https://google-developers.appspot.com/machine-learning/crash-course/backprop-scroll/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDSg-A1h7Qnu",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow provides the tf.GradientTape API that allow to compute the gradient of a computation w.r.t. its input variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2T6RaVB7Qnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute the first derivative of function y=x^3 at x=2\n",
        "x = tf.constant(2.0)\n",
        "\n",
        "with tf.GradientTape() as g:\n",
        "    g.watch(x)\n",
        "    y = #--fill here--#\n",
        "    \n",
        "dy_dx = g.gradient(y, x) \n",
        "print(dy_dx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKdBgtvZ7Qn0",
        "colab_type": "text"
      },
      "source": [
        "By default, the resources held by a GradientTape are released as soon as GradientTape.gradient() method is called.<br>\n",
        "To compute multiple gradients over the same computation,you have to create a persistent gradient tape.<br>\n",
        "This allows multiple calls to the gradient() method as resources are released when the tape object is garbage collected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0G2oKGk7Qn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute the first and second derivative of function y=x^4 at x=3\n",
        "x = tf.constant(3.0)\n",
        "\n",
        "with tf.GradientTape(persistent=True) as g:\n",
        "    g.watch(x)\n",
        "    y = x ** 2\n",
        "    z = y ** 2\n",
        "\n",
        "dz_dx = #--fill here--# # first derivative\n",
        "dy_dx = #--fill here--# # second derivative\n",
        "print(dz_dx,dy_dx)\n",
        "del g  # Drop the reference to the tape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv-BJxLy7Qn4",
        "colab_type": "text"
      },
      "source": [
        "### Keras\n",
        "<img src=\"http://mlclass.epizy.com/lab0_images_notebook/keras.png\" width=\"300px\"><br>\n",
        "\n",
        "Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow.<br>\n",
        "It allows for easy and fast prototyping and supports both convolutional networks and recurrent networks.<br>\n",
        "### Most important features:\n",
        "* User friendliness\n",
        "* Modularity\n",
        "* Easy extensibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqASsWEs7Qn6",
        "colab_type": "text"
      },
      "source": [
        "### Build a Single Layer Perceptron\n",
        "Let's build a single layer perceptron composed by one dense layer.\n",
        "\n",
        "<img src=\"http://mlclass.epizy.com/lab0_images_notebook/simple_nn.png\" width=\"500px\"><br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC8D0f5G7Qn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_dense_layer(x, n_in, n_out):\n",
        "    # n_in: number of inputs, n_out: number of outputs\n",
        "    # y = sigmoid(W*x + b)\n",
        "    # W = [1,1]\n",
        "    # b = 1\n",
        "    \n",
        "    out = #--fill here--#\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XoCVa627Qn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_input = tf.constant([[1,2.]], shape=(1,2))\n",
        "\n",
        "n_in = 2\n",
        "n_out = 2\n",
        "\n",
        "res = # --fill here-- # \n",
        "print(res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR9CYdPZ7QoE",
        "colab_type": "text"
      },
      "source": [
        "### Build the same Single Layer Perceptron with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnG_Y7aS7QoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the number of inputs and outputs\n",
        "n_input_nodes = 2\n",
        "n_output_nodes = 2\n",
        "\n",
        "# First define the model \n",
        "model = tf.keras.Sequential() # model lets us define a linear stack of network layers.\n",
        "\n",
        "# define a single fully connected network layer\n",
        "# look at https://keras.io/layers/core/ to see which parameters takes as input\n",
        "dense_layer = #--fill here--#\n",
        "\n",
        "# Add the dense layer to the model using add() function\n",
        "# --fill here --#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fSteoDv7QoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test model\n",
        "x_input = tf.constant([[1,2.]], shape=(1,2))\n",
        "print(model(x_input))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V4k9SV-7QoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compare the results obtained\n",
        "print(tf.reduce_all(tf.equal(model(x_input),one_dense_layer(x_input, n_in=n_in, n_out=n_out))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BtFApPA7QoR",
        "colab_type": "text"
      },
      "source": [
        "### Build a Multilayer perceptron\n",
        "Let's build a multilayer perceptron; MLPs are fully connected, each node in one layer connects with a certain weight to every node in the following layer.\n",
        "\n",
        "<img src=\"http://mlclass.epizy.com/lab0_images_notebook/mlp.png\" width=\"500px\"><br>\n",
        "\n",
        "Try to build one composed by two hidden dense layer with ReLU activation and one dense output layer(units=1) with sigmoid activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyaSr2017QoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate dummy data\n",
        "data = np.random.random((1000, 100))\n",
        "labels = np.random.randint(2, size=(1000, 1))\n",
        "\n",
        "units = 32\n",
        "input_dim = 100\n",
        "\n",
        "model = #--fill here--#\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "model.fit(data, labels, epochs=30, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}